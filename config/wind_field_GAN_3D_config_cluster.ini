[DEFAULT]

name                    = RF
model                   = wind_field_GAN_3D
use_tensorboard_logger  = True
scale                   = 4
# Remove the `= <num>` to use CPU 
gpu_id                  = 0
also_log_to_terminal    = True
# Set this to true to use the generator_load_path, discriminator_load_path, and state_load_path to load a model.
load_model_from_save    = False
# Progress bar
display_bar             = True


[ENV]
root_path = /cluster/home/jawold/GAN_SR_wind_field

log_subpath  = /log
tensorboard_subpath = /tensorboard_log
runs_subpath = /runs
fixed_seed = 2001
# If this has a value, and load_model_from_save = True, then G is loaded from this.
generator_load_path
# If this has a value, and load_model_from_save = True, then D is loaded from this.
discriminator_load_path
# If this has a value,  load_model_from_save = True, and resume_training_from_save = True then training is resumed from this state.
state_load_path 

[GAN]
#LR input channels
include_pressure = False
include_z_channel = True 
include_above_ground_channel = False
number_of_z_layers = 10 
#2D or 3D, or (experimental) horizontal3D
conv_mode = 3D 
start_date = [2017, 8, 4]
end_date = [2020, 10, 25]
interpolate_z = True
use_D_feature_extractor_cost = False
enable_slicing = True
slice_size = 64

[DATASETTRAIN]
num_workers = 4
batch_size  = 32
name  = WholeDataSet
data_aug_flip = True
data_aug_rot = True

[DATASETVAL]
num_workers = 4
batch_size  = 32
hr_img_size = 128
name  = Validation
data_aug_rot = True
data_aug_flip = True

[DATASETTEST]
#num_workers = 8, batch_size  = 1, no data_aug
mode = hrlr 
name  = Test

[GENERATOR]
norm_type           = 'l1'
act_type            = leakyrelu
layer_mode          = CNA
num_features        = 128
terrain_number_of_features = 16
num_RRDB            = 16
num_RDB_convs       = 5
RDB_res_scaling     = 0.2
RRDB_res_scaling    = 0.2
in_num_ch           = 3
out_num_ch          = 3
RDB_growth_chan     = 32
hr_kern_size        = 5
weight_init_scale   = 0.1
lff_kern_size       = 1
dropout_probability = 0.1
#not currently in use
max_norm = 1.0

[DISCRIMINATOR]
norm_type       = batch
act_type        = leakyrelu
layer_mode      = CNA
num_features    = 32
in_num_ch       = 3
feat_kern_size  = 3
weight_init_scale   = 0.2
dropout_probability = 0.2

[TRAINING]
# See [ENV]
resume_training_from_save = False
learning_rate_g = 8e-5
learning_rate_d = 8e-5
adam_weight_decay_g = 0
adam_weight_decay_d = 0
adam_beta1_g = 0.9
adam_beta1_d = 0.9

# LR is decayed by factor lr_gamma for each entry in multistep_lr_steps if multistep_lr = True
multistep_lr = True
multistep_lr_steps = [10000, 30000, 50000, 70000, 100000]
; multistep_lr_steps = [20000, 60000, 100000, 140000, 200000]
lr_gamma = 0.5
gan_type = relativisticavg

adversarial_loss_weight = 0.0005
#not in use unless use_D_feature_extractor_cost = True
feature_D_loss_weight = 0.05 
feature_D_update_period = 10000
gradient_xy_loss_weight = 3.064
gradient_z_loss_weight = 0.0
xy_divergence_loss_weight = 0.721
divergence_loss_weight = 0.366
pixel_loss_weight = 0.136
pixel_criterion = l1

# How often D is updated relative to G. 
d_g_train_ratio = 1
d_g_train_period = 50
use_noisy_labels = False

use_one_sided_label_smoothing = True
flip_labels = False
use_instance_noise = True
#training iterations
niter  = 150000 
val_period = 2000
save_model_period  = 25000
#save training loss to tb, save generated fields during training
log_period = 1000 
#train/eval&test split
train_eval_test_ratio = 0.8